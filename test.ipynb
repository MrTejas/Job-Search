{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.accuracy import rmse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, KNNWithMeans\n",
    "import random\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "import os\n",
    "from resume_parser import parse_resume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate \"Match\" score using TF-IDF (can replace this with the gemini-api function)\n",
    "def calculate_match_TFIDF_features(cv_text, job_desc):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([cv_text, job_desc])\n",
    "    return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "\n",
    "\n",
    "\n",
    "def get_utility_matrix(users, jobs=pd.read_csv(\"./jobs_dataset/cleaned_dataset/cleaned_jobs_data.csv\"), K=1000, new_user_flag=False):\n",
    "    # Prepare random samples (K = 1000 for example)\n",
    "    # K = 1000\n",
    "    N = len(users)\n",
    "    M = len(jobs)\n",
    "\n",
    "    random_samples = []\n",
    "\n",
    "    random.seed(datetime.now().timestamp())\n",
    "    user_idxs = np.random.randint(0, N, size=K)\n",
    "    job_idxs = np.random.randint(0, M, size=K)\n",
    "\n",
    "    for i in range(K):\n",
    "        user_idx = user_idxs[i]\n",
    "        job_idx = job_idxs[i]\n",
    "        user = users[user_idx]\n",
    "        job = jobs.iloc[job_idx]\n",
    "\n",
    "        match_score = calculate_match_TFIDF_features(user[\"CV\"], job[\"Job_Desc\"])\n",
    "        pay = (job[\"Min_Salary\"] + job[\"Max_Salary\"]) / 2 if job[\"Min_Salary\"] != -1 else np.nan\n",
    "        rating = job[\"Rating\"]\n",
    "\n",
    "        # Example Black-Box Prediction\n",
    "        predicted_rating = (\n",
    "            0.4 * match_score +\n",
    "            0.2 * (user[\"Preferred_Location\"] == job[\"City\"]) +\n",
    "            0.3 * (pay / user[\"Pay_Expectation\"] if not np.isnan(pay) else 0) +\n",
    "            0.1 * rating\n",
    "        )\n",
    "        random_samples.append((user_idx, job_idx, predicted_rating))\n",
    "    \n",
    "\n",
    "    # adding extra pre-matrix-factorization initialization for new user based on TIF score of resume and Job-description\n",
    "    if new_user_flag:\n",
    "        user_idx = N-1\n",
    "        job_indices = np.random.randint(0, M, size=int(0.1*M))      \n",
    "        user = users[user_idx]\n",
    "        for job_idx in job_indices:\n",
    "            job = jobs.iloc[int(job_idx)]\n",
    "\n",
    "            match_score = calculate_match_TFIDF_features(user[\"CV\"], job[\"Job_Desc\"])\n",
    "            pay = (job[\"Min_Salary\"] + job[\"Max_Salary\"]) / 2 if job[\"Min_Salary\"] != -1 else np.nan\n",
    "            rating = job[\"Rating\"]\n",
    "\n",
    "            # Example Black-Box Prediction\n",
    "            predicted_rating = (\n",
    "                0.4 * match_score +\n",
    "                0.2 * (user[\"Preferred_Location\"] == job[\"City\"]) +\n",
    "                0.3 * (pay / user[\"Pay_Expectation\"] if not np.isnan(pay) else 0) +\n",
    "                0.1 * rating\n",
    "            )\n",
    "            random_samples.append((user_idx, job_idx, predicted_rating))\n",
    "\n",
    "\n",
    "\n",
    "    N = len(users)\n",
    "    M = len(jobs)\n",
    "    P = np.zeros((N,M))\n",
    "    for tup in random_samples:\n",
    "        i,j,r = tup\n",
    "        P[i,j] = r\n",
    "\n",
    "    samples_df = pd.DataFrame(random_samples, columns=[\"User\", \"Job\", \"Rating\"])\n",
    "\n",
    "    return P, samples_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black-box function for extracting location and pay\n",
    "def extract_location_and_pay(resume_str):\n",
    "    \"\"\"\n",
    "    A black-box function that processes the resume string to return:\n",
    "    - Preferred_Location: str\n",
    "    - Pay_Expectation: int\n",
    "    \"\"\"\n",
    "    # Dummy implementation (replace with actual logic)\n",
    "    if \"New York\" in resume_str:\n",
    "        location = \"NY\"\n",
    "    elif \"California\" in resume_str:\n",
    "        location = \"CA\"\n",
    "    else:\n",
    "        location = \"Other\"\n",
    "\n",
    "    if \"high salary\" in resume_str:\n",
    "        pay = 100000\n",
    "    elif \"entry-level\" in resume_str:\n",
    "        pay = 50000\n",
    "    else:\n",
    "        pay = 75000\n",
    "\n",
    "    return location, pay\n",
    "\n",
    "def extract_users(resume_df, categories):\n",
    "    df = resume_df\n",
    "    selected_categories = categories\n",
    "    filtered_df = df[df[\"Category\"].isin(selected_categories)]\n",
    "    \n",
    "    users = []\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        cv = row[\"Resume_str\"]\n",
    "        location, pay = extract_location_and_pay(cv)  # Extract location and pay\n",
    "        user_dict = {\n",
    "            \"CV\": cv,\n",
    "            \"Preferred_Location\": location,\n",
    "            \"Pay_Expectation\": pay\n",
    "        }\n",
    "        users.append(user_dict)\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 users extracted from selected categories  ['INFORMATION-TECHNOLOGY']\n"
     ]
    }
   ],
   "source": [
    "resume_file = \"./user_dataset/Resume/Resume.csv\"\n",
    "df = pd.read_csv(resume_file)\n",
    "selected_categories = [\"INFORMATION-TECHNOLOGY\"]\n",
    "users = extract_users(df,selected_categories)\n",
    "print(len(users), \"users extracted from selected categories \",selected_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2849 jobs extracted\n"
     ]
    }
   ],
   "source": [
    "jobs = pd.read_csv(\"./jobs_dataset/cleaned_dataset/cleaned_jobs_data.csv\")\n",
    "# users = [\n",
    "#         {\"CV\": \"Machine learning and Python experience\", \"Preferred_Location\": \"NY\", \"Pay_Expectation\": 100000},\n",
    "#         {\"CV\": \"Sales and Marketing Experience\", \"Preferred_Location\": \"CA\", \"Pay_Expectation\": 50000},\n",
    "#         {\"CV\": \"Management Experience\", \"Preferred_Location\": \"NY\", \"Pay_Expectation\": 200000}\n",
    "#          ]\n",
    "print(len(jobs), \"jobs extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P =  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "shape of P :  (120, 2849)\n",
      "0.028793728793728792 fraction of non-0 entries\n"
     ]
    }
   ],
   "source": [
    "P,samples_df = get_utility_matrix(users, jobs, K=10000)\n",
    "N = len(users)\n",
    "M = len(jobs)\n",
    "print(\"P = \",P)\n",
    "print(\"shape of P : \",P.shape)\n",
    "print(np.count_nonzero(P)/(N*M),\"fraction of non-0 entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization_1(samples_df):\n",
    "    # Convert the utility matrix to a format compatible with Surprise\n",
    "    reader = Reader(rating_scale=(0, 5))\n",
    "    data = Dataset.load_from_df(samples_df, reader)\n",
    "\n",
    "    # Split into training and testing\n",
    "    trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "    # Train SVD\n",
    "    model = SVD()\n",
    "    model.fit(trainset)\n",
    "\n",
    "    # Predict missing ratings\n",
    "    predictions = model.test(testset)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"RMSE:\", rmse(predictions))\n",
    "    print(P)\n",
    "    utility_matrix = P\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            if utility_matrix[i, j] == 0:  # Missing entry\n",
    "                utility_matrix[i, j] = model.predict(i, j).est\n",
    "    print(utility_matrix)\n",
    "\n",
    "    return utility_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    '''\n",
    "    R: rating matrix\n",
    "    P: |U| * K (User features matrix)\n",
    "    Q: |D| * K (Item features matrix)\n",
    "    K: latent features\n",
    "    steps: iterations\n",
    "    alpha: learning rate\n",
    "    beta: regularization parameter'''\n",
    "    Q = Q.T\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    # calculate error\n",
    "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                    for k in range(K):\n",
    "                        # calculate gradient with a and beta parameter\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = np.dot(P,Q)\n",
    "        e = 0\n",
    "\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2)\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "        # 0.001: local minimum\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2069\n",
      "RMSE: 0.20688334437942163\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0.68374854 0.65893502 1.03838854 ... 0.89626532 0.83871323 0.88791164]\n",
      " [0.8688744  0.5499361  0.92822238 ... 0.73193809 0.8275216  0.78564763]\n",
      " [0.71564859 0.69138677 0.84555713 ... 0.76747995 0.82466968 0.83230852]\n",
      " ...\n",
      " [0.89564076 0.69045007 0.93455258 ... 0.66094277 0.98444497 0.83282262]\n",
      " [0.8167667  0.69134954 0.85558509 ... 0.65004102 0.9274587  0.83220007]\n",
      " [0.806967   0.61296818 0.90607237 ... 0.99597632 0.97329295 0.82105959]]\n",
      "New_P = \n",
      " [[0.68374854 0.65893502 1.03838854 ... 0.89626532 0.83871323 0.88791164]\n",
      " [0.8688744  0.5499361  0.92822238 ... 0.73193809 0.8275216  0.78564763]\n",
      " [0.71564859 0.69138677 0.84555713 ... 0.76747995 0.82466968 0.83230852]\n",
      " ...\n",
      " [0.89564076 0.69045007 0.93455258 ... 0.66094277 0.98444497 0.83282262]\n",
      " [0.8167667  0.69134954 0.85558509 ... 0.65004102 0.9274587  0.83220007]\n",
      " [0.806967   0.61296818 0.90607237 ... 0.99597632 0.97329295 0.82105959]]\n",
      "New_P shape = \n",
      " (120, 2849)\n"
     ]
    }
   ],
   "source": [
    "new_P = matrix_factorization_1(samples_df)\n",
    "print(\"New_P = \\n\",new_P)\n",
    "print(\"New_P shape = \\n\",new_P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_new_user_to_utility_matrix(cv_text, preferred_location, pay_expectation):\n",
    "    \"\"\"\n",
    "    Adds a new user to the utility matrix and calculates predicted ratings using collaborative filtering.\n",
    "    \n",
    "    Parameters:\n",
    "    - utility_matrix: np.ndarray of shape (num_users, num_jobs), existing matrix with user-job ratings.\n",
    "    - jobs_df: pd.DataFrame containing job information.\n",
    "    - city: str, current city of the user.\n",
    "    - preferred_location: str, user's preferred location for jobs.\n",
    "    - pay_expectation: float, user's expected salary.\n",
    "    \n",
    "    Returns:\n",
    "    - new_P: np.ndarray, utility matrix with the new user added.\n",
    "    - recommendations: list, predicted ratings for the new user for all jobs.\n",
    "    \"\"\"\n",
    "    cv = cv_text\n",
    "    location, pay = preferred_location, pay_expectation\n",
    "    user_dict = {\n",
    "        \"CV\": cv,\n",
    "        \"Preferred_Location\": location,\n",
    "        \"Pay_Expectation\": pay\n",
    "    }\n",
    "    users.append(user_dict)\n",
    "    P, samples_df = get_utility_matrix(users, jobs=pd.read_csv(\"./jobs_dataset/cleaned_dataset/cleaned_jobs_data.csv\"), K=1000, new_user_flag=True)\n",
    "    new_P = matrix_factorization_1(samples_df)\n",
    "    recommendations = new_P[len(new_P)-1]\n",
    "    \n",
    "    return new_P, recommendations\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2328\n",
      "RMSE: 0.2327844644055725\n",
      "[[0.68374854 0.65893502 1.03838854 ... 0.89626532 0.83871323 0.88791164]\n",
      " [0.8688744  0.5499361  0.92822238 ... 0.73193809 0.8275216  0.78564763]\n",
      " [0.71564859 0.69138677 0.84555713 ... 0.76747995 0.82466968 0.83230852]\n",
      " ...\n",
      " [0.89564076 0.69045007 0.93455258 ... 0.66094277 0.98444497 0.83282262]\n",
      " [0.8167667  0.69134954 0.85558509 ... 0.65004102 0.9274587  0.83220007]\n",
      " [0.806967   0.61296818 0.90607237 ... 0.99597632 0.97329295 0.82105959]]\n",
      "[[0.68374854 0.65893502 1.03838854 ... 0.89626532 0.83871323 0.88791164]\n",
      " [0.8688744  0.5499361  0.92822238 ... 0.73193809 0.8275216  0.78564763]\n",
      " [0.71564859 0.69138677 0.84555713 ... 0.76747995 0.82466968 0.83230852]\n",
      " ...\n",
      " [0.89564076 0.69045007 0.93455258 ... 0.66094277 0.98444497 0.83282262]\n",
      " [0.8167667  0.69134954 0.85558509 ... 0.65004102 0.9274587  0.83220007]\n",
      " [0.806967   0.61296818 0.90607237 ... 0.99597632 0.97329295 0.82105959]]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./user_resume/sample_resume.pdf\"\n",
    "cv_text = parse_resume(file_path,\"text\")\n",
    "loc, pay = extract_location_and_pay(cv_text)\n",
    "\n",
    "new_P, recommendations = add_new_user_to_utility_matrix(cv_text=cv_text, preferred_location=loc, pay_expectation=pay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.806967   0.61296818 0.90607237 ... 0.99597632 0.97329295 0.82105959]\n"
     ]
    }
   ],
   "source": [
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1152, 906, 1188, 779, 761, 2436, 1318, 881, 731, 1146]\n"
     ]
    }
   ],
   "source": [
    "sorted_indices = sorted(range(len(recommendations)), key=lambda x: recommendations[x], reverse=True)\n",
    "T = 10\n",
    "top_T_jobs = sorted_indices[0:T]\n",
    "print(top_T_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_idx in top_T_jobs:\n",
    "    job = jobs.iloc[job_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "\n",
    "# Create a Jinja2 environment\n",
    "env = Environment(loader=FileSystemLoader('.'))\n",
    "\n",
    "# Define a template for the HTML page\n",
    "template = env.get_template('./web/job_template.html')\n",
    "\n",
    "# Prepare the data for the template\n",
    "job_data = []\n",
    "for job_idx in top_T_jobs:\n",
    "    job = jobs.iloc[job_idx]\n",
    "    job_data.append({\n",
    "        'title': job['Job_title'],\n",
    "        'company': job['Company'],\n",
    "        'state': job['State'],\n",
    "        'city': job['City'],\n",
    "        'min_salary': job['Min_Salary'],\n",
    "        'max_salary': job['Max_Salary'],\n",
    "        'job_desc': job['Job_Desc'],\n",
    "        'industry': job['Industry'],\n",
    "        'rating': job['Rating'],\n",
    "        'date_posted': job['Date_Posted'],\n",
    "        'valid_until': job['Valid_until'],\n",
    "        'job_type': job['Job_Type']\n",
    "    })\n",
    "\n",
    "# Render the template with the job data\n",
    "html_content = template.render(jobs=job_data)\n",
    "\n",
    "with open('./web/top_jobs.html', 'w', encoding='utf-8') as f:\n",
    "  f.write(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
